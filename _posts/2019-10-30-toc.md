---
title: 'Types of Analytical Computing'
date: 2019-10-30 00:00:00
description: Setting the foundation for analytical computation discussions
featured_image: '/images/blog/IcelandGlacier.jpeg'
---

![](/images/blog/IcelandGlacier.jpeg)

## Setting the foundation for analytical computation discussions
We submit our job, wait, and we get an answer.  This is great when we are discovering and developing. When you trying to scale frequency, size, response time, and/or quantity you probably want faster run times.  Faster also opens doors to more methods and approaches.  In my experience, faster breeds creativity!
To kick this blog off I want to break faster down into four types (and a few subtypes).  We will refer back to these in future posts, as well as, dive deeper into them.  For the time being, we will take data size and I/O speed out of the conversation.  

### A quick lingo check
* Session - the invocation of the software system you are using. In batch processing this can be tied to a job submission.
* Jobs - the full set of code you are submitting for execution 
* Steps - the individual commands in the code that request computation and wait before proceeding   
* Process - the action level of the runtime engine you are using.  This may be congruent to the step level but frequently a software system (Python, R, SAS, various packages within these, etc.) will break down user-submitted steps into finer levels of action which may or may not be directed by user input.
* Thread - the execution sequence of instructions submitted to a processor

### Types of Computing
* [Single-Threaded:](#single-threaded) process running on a single thread
* [Sequential Single-Threaded:](#sequential-single-threaded) processes running on a single thread, sequentially
* [Parallelization:](#parallelization) Splitting a process into processes that run in parallel
* [Multi-Threading:](#multi-threading) Spreading a process over multiple threads = multi-threaded
* [Distributed Computing:](#distributed-computing) Spreading a process over multiple threads and machines

### Single-Threaded
Some processes are only designed to run on a single thread.  At this core level of execution, generating faster run times may be achieved with faster processors, less competition for computing resources, and faster I/O.  

![](/images/blog/toc/toc/single.gif)

### Sequential Single-Threaded
When a process is instructed to run on multiple subsets of data (states, patients, companies, etc.) then these may execute one-at-a-time.  There may still be some optimization designed into the execution such as fully loading all the data to memory at the start of the process.  This is important to understand because the size of data may require manually running the subsets separately on the system you are executing on. 

![](/images/blog/toc/toc/sequential.gif)

### Parallelization
Parallelization involves programmatically instructing sequential computations to compute at the same time.  It is important to consider the computation time for the individual processes as this method can only be as fast as its slowest single-threaded process.  It is important to design your code to create parallel processes and manage them before continuing to further steps.  This method can be used in a scaled-up environment (bigger hardware with more cores) and a scaled-out environment (more hardware).  This method can also be used to overlap related sequential processes through pipelining - where one process's output feeds another process's input dynamically.  It is also beneficial to consider using a load balancer to manage the individual processes in a scaled-out environment. 

![](/images/blog/toc/toc/parallel.gif)

### Multi-threading
Some processes may be fully or partially designed to work multi-threaded, where multiple cores on a single machine can simultaneously work on the same process.  Many algorithms have been vastly improved recently to take advantage of multi-threading.  Sometimes, the process is just optimized to handle parallelization opportunities via multi-threading.  I suggest checking your software systems for updates to existing procedure steps or new replacement procedure steps that are capable of multi-threading.  An important system consideration is that there may be a constraint on any running job to work on a sub-capacity of the total system which will limit multi-threaded computations.  We will cover this in more detail in the future but I frequently test my jobs across a range of thread-counts to find a locally optimal value for my process.  At the programming level, you should test and consider the impact of multi-threading for your current data and process.  Some situations can slow down with more threading. 

![](/images/blog/toc/toc/multithread.gif)

### Distributed Computing
Think about multi-threading where the threading is distributed to more than one piece of hardware.  The cores of multiple machines simultaneously work on the same process or action.  This typically also involves in-memory processing where data is partitioned and subsets of rows are loaded to each machine in a distributed cluster.  Depending on the type of process being requested the threads may work independently and then collect the final answer at the end of processing or they may simultaneously compute and communicate with each other to create the final answer.  One example is calculating a mean: each thread can sum and count a small subset of data then the collection phase just has to sum the sums, sum the counts, divide, and get the overall mean.  Another example is calculating a median: each thread will need to communicate with the other threads to compare values and ranges before estimating the actual median across all the rows of the full data.  

![](/images/blog/toc/toc/distributed.gif)
